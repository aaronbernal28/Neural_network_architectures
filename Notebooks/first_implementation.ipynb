{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqImrIb7RqGs"
      },
      "source": [
        "# Backpropagation y descenso de gradiente\n",
        "\n",
        "El objetivo de este Colab es implementar el método de descenso de gradiente para el entrenamiento de una red neuronal.\n",
        "\n",
        "Usaremos las redes neuronales feedforward que implementamos en el Colab anterior.\n",
        "\n",
        "Antes de empezar con el código vamos a tomarnos un tiempo para hacer un repaso del funcionamiento y las ideas principales que conlleva un proceso de entrenamiento de una red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPUzRQvBSYcw"
      },
      "source": [
        "## Repaso del método\n",
        "\n",
        "Se tiene una red neuronal feedforward como en el siguiente gráfico\n",
        "\n",
        "![NN.jpg](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAASABIAAD/4QBARXhpZgAATU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAABR6ADAAQAAAABAAAAqgAAAAD/4gJASUNDX1BST0ZJTEUAAQEAAAIwQURCRQIQAABtbnRyUkdCIFhZWiAH0AAIAAsAEwAzADthY3NwQVBQTAAAAABub25lAAAAAAAAAAAAAAAAAAAAAAAA9tYAAQAAAADTLUFEQkUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAApjcHJ0AAAA/AAAADJkZXNjAAABMAAAAGt3dHB0AAABnAAAABRia3B0AAABsAAAABRyVFJDAAABxAAAAA5nVFJDAAAB1AAAAA5iVFJDAAAB5AAAAA5yWFlaAAAB9AAAABRnWFlaAAACCAAAABRiWFlaAAACHAAAABR0ZXh0AAAAAENvcHlyaWdodCAyMDAwIEFkb2JlIFN5c3RlbXMgSW5jb3Jwb3JhdGVkAAAAZGVzYwAAAAAAAAARQWRvYmUgUkdCICgxOTk4KQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWFlaIAAAAAAAAPNRAAEAAAABFsxYWVogAAAAAAAAAAAAAAAAAAAAAGN1cnYAAAAAAAAAAQIzAABjdXJ2AAAAAAAAAAECMwAAY3VydgAAAAAAAAABAjMAAFhZWiAAAAAAAACcGAAAT6UAAAT8WFlaIAAAAAAAADSNAACgLAAAD5VYWVogAAAAAAAAJjEAABAvAAC+nP/AABEIAKoBRwMBIgACEQEDEQH/xAAfAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgv/xAC1EAACAQMDAgQDBQUEBAAAAX0BAgMABBEFEiExQQYTUWEHInEUMoGRoQgjQrHBFVLR8CQzYnKCCQoWFxgZGiUmJygpKjQ1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4eLj5OXm5+jp6vHy8/T19vf4+fr/xAAfAQADAQEBAQEBAQEBAAAAAAAAAQIDBAUGBwgJCgv/xAC1EQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2wBDAAICAgICAgMCAgMFAwMDBQYFBQUFBggGBgYGBggKCAgICAgICgoKCgoKCgoMDAwMDAwODg4ODg8PDw8PDw8PDw//2wBDAQICAgQEBAcEBAcQCwkLEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBD/3QAEABX/2gAMAwEAAhEDEQA/AP38ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKwPFWpT6N4a1TVbYZmtbaWRO/zKpwT7A00rkzkopyfQxfEPxH8HeF7k2Wq34FyOsUatIy5/vbQQv0JzWn4c8YeHPFkTyaFercGP76YKyL7lWAOPfGPevzxmmluJnuJ3MksrFmZjksxOSST1JNdD4P1q80DxLp+p2TMHjmQMq/xoxwyY75HFdzwito9T5SnxFN1FzRXL+J+idFeQf8Lisv+hT8Tf8AgmuP8KP+FxWX/Qp+Jv8AwTXH+FcB9aev0V5B/wALisv+hT8Tf+Ca4/wo/wCFxWX/AEKfib/wTXH+FAHr9FeQf8Lisv8AoU/E3/gmuP8ACj/hcVl/0Kfib/wTXH+FAHr9eNeI/j98KvDGovpN/rIluYmKyLbxvMqEdQzoCuR3AJI7ivGviH+0LcaroPjrw1oegaxol5osGnAX95ayW8TLqTMrRqzAFZ41Qkp2SSNw3zEL8A1+teHvh5RzSjPFYqbUU7JK127JtttPTU4cXi3B8sT9o/C3jDwz4107+1fC+oR6hbZ2sUJDI3o6MAyn2YCulr8r/wBnDxJqWhfFTS7O0dvs2rFra4jB+V1KkqSPVWAIPpkdzX6oV8xxzwqsoxnsIS5oyV03va7Vn56G2Gr+0jcKKKK+MOgKKKKACiiigAooooAKKKKACiiigAooooA//9D9/KKKKACiiigAooooAKKKKACiiigAooooAKKKKACvMfi947074f8Age91e90yfX5rkraW2lWhX7ZqM052+RbqxAZym5sZGFViSACR0HjXxro/gXRxqmqCSeWeRbe0tLdfMury6kz5cEEeRudsHuFVQWYqisw5TwV4K1iXWD8RfiKY5/E88bR21tG3mWukWsmCbe3JA3SNgefPgNIwwAsaqoAaPm29+FXi1rS01fR9OmuLHUIY7iNG2i4hWVQ4jmjB4kXOG25XI4NeWa/qkfgPxdZ+E/E9o1vqt3BFdQRXLyWts8TymP8AeXkRzBkqyCRdzROUkdREHdf0+r5X/at+HQ8T+DLXx1pyKNX8Fu90HaLzg1jIAt2jx4JkjCASPEP9aqNF0kaul4qTVjxaeRUI1OfX06FvwVqnjy4trk+A9fOsyaW4ivvDvitfJ1OxkIyIzfW6swUjlJJIblZR8ySlea7uH4z6HpcyWPxI0+78D3bsED6mq/YJGPA8vUIme1+Y/dV3SQ/3AeB84fD+S216PQ7C4v5tA1eMS2nhzW0cTz2k8HzXGhXzMdt1HHt32/mHFzb7ZEYSoJW+mPDPjyW/1I/D74kWEWkeJZI32RZL2OqQqPnlspHHzjHMkLfvY/4gybZG5j2j1WKWK4iSeB1kjkAZWUgqynkEEcEGpK+RtbT4b6DqtzYfBHUNTtfEcTnzdN8KIl5YrKeSt3bTZ022LE/MztbyHPD9DVe51j9qjyLf/hObG30zRWU+fc+EokvdXUZ6yQXrvHFx1W3W8fJ+UjGaAPp7xN4v8LeC9P8A7U8WatbaRaltivcyrGHc9EQMcu57KoJJ4Arzv/hYXjXxX+7+G/hSZbV+mqa9v021x/eitSpvJfUBooUbjElZPw1tvga0934k8MXkOpa5YRsb6+1WaSbWLZAMsLg3p+02y45MZWNAOigYqlrHi/UfiNpl5qWl6k/hP4cWUTzXmvM3kXWoQRgl/sJbBgt8A5uj8zj/AFAAKzUAfIH7RPjTU/h3qupeNPFGs6h8QtFt7L+yPFNtpu2w0vSC88c8E1pbZlFzfw7X2wPKzhWzLLGhXHnHhXwDrnxF8NWHjr4XqPF3hfV95stRsgVSURu0bh4pQksTq6lWWRFIIPUc16h8QdNvfG93oXw98L6aNCh1LZa6Tpfl7Rpmn3of9/dRnk3l7Ek086vlo7OKSJiJbhi36J+CPA3hb4deG7Twp4P06HTdOs0VQkSKhkcKFaWUqBvlfALu2WY8k5r7ThXjrGZQpQoJSjLWzvv3Vmjnr4aNTc+Kvht8N9V+Cmr6d8S/iZYeVpi+bDJJE4kOltKAqXV0FyPJILI7qx8rIdwE3Mn6AI6SoskbB0cAqQcgg9CDSSxRzxvDMgkjkBVlYZDA8EEHqDXgINx8B7gI5af4azNhWOWfw8zHoe508noett0/1H+p8biDiDEZliXicS9dklsl2RpSpKC5Yn0DRTUdJUWWJg6OAVYHIIPQg06vENAooooAKKKKACiiigAooooAKKKKACiiigD/0f38ooooAKKKKACiiigAooooAKKKKACiiigArkfGvjXR/AujjVNUEk8s8i29paW6+ZdXl1Jny4II8jc7YPcKqgsxVFZgeNfGuj+BdHGqaoJJ5Z5Ft7S0t18y6vLqTPlwQR5G52we4VVBZiqKzDlPBXgrWJdYPxF+Ipjn8TzxtHbW0beZa6RayYJt7ckDdI2B58+A0jDACxqqgAPBXgrWJdYPxF+Ipjn8TzxtHbW0beZa6RayYJt7ckDdI2B58+A0jDACxqqj1SeeG1gkubhxHFCpd2PRVUZJP0FS15x8UPEfhzRfDMul69rFro8+vhtPsDdzJbrc3k42xW8byEK0srEKiA7mPCg00tSKjai2jwPxP8dfE17fSJ4aZdOskJCExrJK4Hdt4YDPoBx6mug8EfHGWWdtN8eNEbZ0b/StgXbgEkSKowQRxwPwPb5sdGjYo4KspwQeCCOxrQ0eK5l1W0Szjklm81CiRbfMZgQQE3kLuPRQSATgV6kqEOW1j4OhmmI9qpczd3t0+45Nr/UdI1bXfBPh/wAOzr4RuRaQyX+sibTIrewlmCaNqkMbKLwSafIrWjSCNB5UdrK0qhc17/p3wvX4mXV78LP2mtbvPFGs6agubSGJv7M029tV+RL+2itdkjTIW2zJLLL5UhBUBHjJ4j4gWWn+I7M+I7T4p+IrzWPD8E0eq6NqNho1rqLaFd7V1JPscukxSSARoJVyjo5iwpywYbmjfCnxd4glfwHe/FrX4vEXg5U1HwxqXk6NKk2nyoY7W4L/ANniWcKMwXaGXEuA7YEqY8o+/Pa9A1e7+CUNn4N8axwjwnGVg03XbeGO2ghDHCQajFEqxwPk4WdFWGQ8MInKq/r/AIq8XeHvBejPr3iO7FtaqyxphWkkmlkOEihjQF5ZXPCIgLMeADXx5/b/AIk1DS5fB2qePPFGoePm32V34Yjt/D0hZ9o3TO76PsXT5FYOLiQbSjBcGX91XLaZ+zp8VPhTPo3jO/8AiBr3ia10q3lhktLC30yefRklcszaXDdWEyyRIh8t0jSKYov7sFdtuAD3HWvg3afH68tvEfxr0NLTSbPJ0zRw2y9jDDia9u4GEgkwcrbwyCNOrtK+NnjPiabxxLZN4s0HWH8Y/DzQL+3j0jR9aYed4h1MSeXClveQR73t4p9vkGdJhLIplZhFGjt1DaJ4i+Nt6/hTwT8X/EOqeDRCRrmpxRaIqSecmV0+2kh0uNhMQwa4bP7pMRkb5Ds4PxH4c8YatPb6j4a+JWtJZ6Xff2D4Q322iLCb1Y5ItQ1DZHpiJ9ms7dZVQgBsRTbHAkTIBW+CvxL02w+IvibW/iTpWoW+uaRpt7eSXTQiWznujdJa6hNFcxM8OHmjjsrNGYMIbVh1Z6y/Ef7U3xQ1TUXuNDuYdFswx8uGOGOY7e295VYk+pAUe1ZE2jaHpcnjX4beA/H2u+O7RdD028tIJIbebSbeDRphBdBbuzijha7/AHiNKAiF1UFjLIpK+CV++eEvDWAxOFqYnEQU581rNXSVk9nprffy06nl4+tJSUU7H6NfAf8AaCuvH2o/8Ij4ujjj1Yoz288Q2JcBBllZOzgZbjggHgY5+q5Yo5o3hmQSRyAqysMhgeCCD1Br8kvghNaWXxP0LVNSvI9OsbOfdNczuI4k3qURWdsKDI7LGuTyzADk1+uFfE+J+S4XA5ioYRWUoptLZO7+69r2/Q6cFUlKF5Hz8DcfAe4COWm+GszYDHLP4edj0Pc6eT0P/Lr/ANcP9T7+jpKiyxMHRwCrA5BB6EGklijmjeGZBJHICrKwyGB4IIPUGvAQbj4D3ARy03w1mbAJyz+HnY9D1J08nof+Xb/rh/qfzk6z6BopkciSossTB0cAqwOQQehB9KfQAUUUUAFFFFABRRRQAUUUUAFFFFAH/9L9/KKKKACiiigAooooAKKKKACiiigArkfGvjXR/AujjVNUEk8s8i29paW6+ZdXl1Jny4II8jc7YPcKqgsxVFZgeNfGuj+BdHGqaoJJ5Z5Ft7S0t18y6vLqTPlwQR5G52we4VVBZiqKzDlPBXgrWJdYPxF+Ipjn8TzxtHbW0beZa6RayYJt7ckDdI2B58+A0jDACxqqgAPBXgrWJdYPxF+Ipjn8TzxtHbW0beZa6RayYJt7ckDdI2B58+A0jDACxqqj1gkAZPAFefeLviVoPhS8i0KOObWvEV2m+30nT1E15Iucb2BKpDFngyzOkYPG7OAeSHgHxV8QiLr4uXSQ6U/K+HNOkb7GV7C+uMJJdn1jAjg7MkmA1AFi7+KF/wCJ7qbRPg9Yx+IJ4nMU+rTMyaNaOpwwMy/NcyKesVvkAjbJJEeak074MaDc6ha+JfiDcSeMfEdpNFcw3l4NkVpLC4kT7FbIfLt1VlByN0jAASSSV63aWdpp9rDY2ECW1tbosccUShERFGAqquAABwABgVYoA808S/Cbwd4ovG1G7gktbqQ5eS3YIXPqwIZc+pxk96+a/j18Jf8AhE9C0/xT4Wk83SbF/K1i0vHJtpoJGUxzTMoDIkUirukTDQAi5X5oMN9ea14v8M+HXWLWtShtZGGQjNl8eu0ZOPfFImt+FPEWi3k32y1vdL8p1ut7KYhEVO8ShuAu3Od2BjrxWjlO3kccaNBVLpLm/E+VdO1/QtS8KQw/FrTx4o8EwytbnUNThSXUtAvIiFe21YAZUxHAW+jI+Xa8mFInf56k0b4maP4pu/h7+zj4iOua38NpZrrS11OSO902DRLqAFLAXW4XJlzi3EDPKi+VBK/lfKTr2E3iyTXtVsPAs95b+FdNsg813E7Q6h4p8NQyKiNY+an+v09C0ButwknhMWw5kilSXWdd8N/DNtA+JP7KdtceM/CfhhLie+0jTo5HsrfS7lN96LS/kHlBtyJO9mXd/OjBQRkukmZ2HV6Hr9l4e8O6Z8XbXS9Q0jxZLF9oudavpPtun67C2POs769hRfsgUqRD9ogtltZV2qgQyI/qXiz9qHwLrug6Hpfw+8Rw2+q+K4jJ5237RcaZbKxSZvssYkea7Dq0cECKxaRWcgxRua8PuPG3jKG7sb7w94htrbQ/ixdTtpWlaBcANDrbeWssd1e3UKzQQSZMtwYYIpI5lZR+9mUNtat+zV4W/Zt0sfGLwhqup2F7ZwM3iu+srlvtd8jN5jXqRXBmimkgcnEEqSeZF8q5mClgDK8VaR8R9PurTwP+y5oNz4NvfEtpdG9k1y48sXVtHHiXUntF8yaK7eRlRbmV4ZZJXHmRyKu+Ov8ADWD4T6/cX3ir4kXdz4htfBjReGtF8N30cTvFeRqDcR2+k2uYZN0kYghY+bkW7ymZkO9at18Vfi94M0j7Xpdvp/jz4kfFu0hbShYTiG+020Nu72nnxBZLbyYIhLOzLKnmTGXy0ccrr6XoHgjT7bw9pPgrWrqf45Rwx2GmG4hl0+bTLWJf3qy2NyM/2Yi7mmLh2uZCCJTM0bqAc5+0poPi74gnRrWCUeH/AB1os1vN4es9OSCdPD8tw220W4dlZbi9umQYiUrDBFG83zLCJJPpDQ/2WtB1Tw7pU3xFkVPFKQKupzaK3kWVzcLw00cMkZ8oSY3FFCqpJA4GT5t8Bdc0VfGEFz8R51tNVjnnt9FuJC7w+ItQnkMF9rFvMyKJGl2rDDEADb24IXMMisfrzX/ir8OvC98dM13X7W1u1OGi3b3Q+jhAxX8cV7eR4zMKVR/2c5KT35b7eaRnUjBr3xfC3wv8DeD9DufD2j6TEbO+UpdCdRMblSMESl87lwT8p+Xk4HNcf/wgni34d/6T8JrpbvSE5bw7qMrfZ1XuLC6IeS2PpE4kg6KqxDLV65pGtaR4gsU1PQ72G/tJPuywOJEJHUZXPI7jqK0687G1q1SrKeIbc3ve97+dy4pJaHn3hD4k+H/F13Nom2bSPEFmge60m/QQ3sK5xvC5ZZYieBLCzxHoGzkV30sUc0bwzIJI5AVZWGQwPBBB6g1yfi/wL4Y8c2kNv4htPMltHMlrdRO0F3aS4x5lvcRlZIn90YZHByMivP8A+1viP8M/k8SRTeN/DSdNQtIR/a9qg73NpEAt0o7yWyrJ/wBMG5euUZmA3HwGuAjlpvhrM2ATln8Pux6HqTp5PQ/8u3/XD/U+/wAciSossTB0cAqwOQQehB9Kw9C8QeG/Gmipq/h+9t9X0y7DKJImEkbdmRh2I6Mrcg5BAPFeOA3HwGuArFpvhrM3BOWfw87HoepOnk9D/wAu3/XD/UgH0FRTI5ElRZYmDo4BVgcgg9CD6U+gAooooAKKKKACiiigAooooA//0/38ooooAKKKKACiiigAoornNW8T6dpMn2d90sw6qmOPqT0rGvXhTjzVHZGlKjKb5YK7OjrkfGvjXR/AujjVNUEk8s8i29paW6+ZdXl1Jny4II8jc7YPcKqgsxVFZhmX3xF0uw0q61FrS5uJrdMx20CCSa4kJwkUQyAXdiFG4qMnJIGSPAPC2ueJvFviKfxVodjb+J/FzB7Zb1pG/wCEc8OwMfntYLhRuvLjgfaGgBMjjY7wIEUFDEQqx5qbuh1qE6b5ZqzPStOsbbwq03xh+Nmo2tprBjMMCNJm00iCYjFpak4Mk0hAEsoG+Z8KoCBEE/8AaXxI+Jny6DHP4F8NSdb65iH9s3aH/n3tpQVtFPZ51aX/AKYocNW14f8Ahjp2mamnjHxpqD+KPEkAYrf3iqkNoCPmFlbA+VbLjgsuZWHEkj9afqfxs+E2lXbadL4psbq/TraWUn266H/bvbeZL/47WxkdL4R8DeGPA1nLaeHLMQNdP5tzcSM011dS4x5txPIWlmf/AGnYnHAwMCutrx7/AIWxqOpceEvAniHVw3SWe1j0mIe7DUpbabH+7Ex9qPtnx51j/j303w/4Yjbo9xcXOrzAerQxJZID7Cdh70Aew1yfiTxZpmiWmpwxXcD6tY2L3wtPMXzvKG5UkMed3ll1K7sYyCM5FcV/wrrxzqvPif4i6kyn70Gk21ppsB/4E0dxcj2xcD8ayx+zl8L38Uab4zvra+1PWtJt723trrUNRu7+SL7fF5MzqbmWTaxiLIAuFAZsL0w1vqTNNxfLufI17e3epXc1/fStPcTsXd2OSzHvT7HZLMtjcRxT2108Syw3MZnt5Nkiunmwhk81FdVYoWAbGCcGu48UfC/xb4cvpIFsZb613Hy54EMisvbcFyVPqD36EjmsC68Pa/4at7LXNZ0m7jt7m5it4AGW1kknkYBI1klBWKRxnyWlCxvKEiLqZAa9aVSPLfofn1DCV/bJJPmuXPiDpnw98V6VB4i1rVdc8Z+LtBkF5p0WqaFqUels6EGS0+wxWS24iuFHll5FkkQ7X3kqKjP7S3wm+FFgfiBoUWpf8IB4i3m/0oaPexNpmqHcHMAeFYcSyqYbmEPhZv3o4Mxr2rR/iJ410jwrd+MrPVbLxx4b0pZTfC+CaJrdgYBmWO5UhbVpkH3kdLTA5yQQT89+GPiR4HtPi+PHvxQhPhLQfFclz9g0bX4nsTpl3LAiG/lS4AgkbUIUZJHiZ1gJVC2+4mJ8g/QzyXwZoPhMW3iqzubm/wBI8bXMUTW0I0nVJbOTQnWN7K0DR2fmxyWE0Xlx3ir5gkijkPmR7YRsaN+1ZqP7QOraJ8OFS40e88FkT+J7ttMurxBqdtK0ds0VrbxSFypj+0qkgWJZim8t5JjkofGrxB4v8J2ujT+HDeaR4KeS6svDVxMssN/eafciJrqwkKyLPFYRIhubclVnmSFYFMZMZm9T/aE+HHgf4JfC/wAGeNPhrf8A9g6x4eiOm2upWYAuJrO5V7m5usRDbMYSJLwxkFJV8yILmVMAHmvhP4o/CT4A+O9Z+IGk2Wral4MuJbrTdNaWwvPtT6zIkbXlyHlt40ZbyeE2+CwNu8TFUWCRvL9J8V658PPGcKeFPGUNzrPjHxk8Vxrd6dB1KT+xtKgLERWHmWnmRhSTBBIoDGV5LhsMCta3w88TeF/BPhWDxB+0TaRaXY2eheR4cjljVtNuNJe3Hm+UGklB1K8XmeGRzIVISMyL5jvV+BnxE1rwTdyaFa6JceK7/wAaSwvpWrSTPBpkEcULeTo0mpXKkT/YolPlSWyz+dmRtu8OWAOA1+4+Ha+LNdj8JalqWo2fwy0jTV0XRNf02SaLS7nU7geRqVjdXy/aYngS1eKJWAdSCysU248QkkeV2llYu7klmJyST1JJ719K/tAeN9c8E+ILqf4o62dQ8PanYpba5p/h2wkuLXQJWmjax1K9cpNPKww0YWMwvMpUCFgoI8v134RfEbQLz7LcaDd3SPzHNawvPDKp5DK6Keo5wcMO4Br+hfBzM8FTw1WjOSjVcr66NqytbvZ306X8zyswhJyT6Hffs0+MdT8O/Emx0WGVjp+uFoJ4c/KW2kxuB/eVgBn+6SK/UKvgr4Ffs63096/iP4maUi2HlSRw6fdoGMxlUozSxtnaoUnCsM7sHAwM/Sn/AApLwxY/N4V1TWvDTDothqtyYF/3bW4ea2H4RV8L4q4/CYjM+bCtO0UpNbN3f32Vlf5dDpwMZKHvHsNFePf8Ip8YtI50Tx3bavGv8GuaVHJIw9PO0+SzVT7+S30o/wCEo+Mmkca14HtNYjX+PRNVRpWH/XC/itEU+3nt9a/NDsLviL4XWd3q03i3wVfyeFPE02DLd2qB4LwqMAX1qSI7gY43HbKo4SVKyrb4mXGhTx+HPjJp0WgT3REEWooxl0W9Z/lCrO4Bgkfp5NwFyTtjeXrVj/hdfhyx+XxXo+ueGmHU3ulXDwL/AL11arPbD8ZfpXS6R44+GfxEtJ9M0TXdJ8RwXCNHNbw3EF0GUjDJJEGbtwVYexFAHnIM/wAB5wrFp/hpO3B5ZvDzMeh6k6cT0P8Ay6/9cP8AU+/xyJKiyxMHRwCrA5BB6EH0rxCX4f8AijwFG7/Cy4jvtFIIk8N6nIxtQh6rY3JDvbccCJxJB/CqxDLV4L4S+NVn4B+J1j8HtA066TSJ7eXUL7TNS22114TtIch2BZitzYSSFY4PIaRY3ZURmRkSMHGLbsj7sor5fvf2qvBVvfGCz029urZTgzAImR6qjNnHpkg+wr3Xwf408PeOtJXWfDtz58Odrqw2yRP/AHXXsf0PUEiqcWj0MVlGJoQU6tNpHV0UUVJ5wUUUUAFFFFAH/9T9/KKKKAMHxRqMuk+HtQ1GBpElhhYo0VrLeurEYVhbwgyS4JztXkjuByPnfwT8TPHdtpfhq/8AHVyIZPEut/2aLXUdPbTbiCJoZ5IkTcyeZLtSISMI9hlMioAMKn1NRQBzfijUvEel2Ec/hjRl1y6aUK0LXKWoWMqSX3urA4IAxjvntXCf8Jh8XP8Aonkf/g5g/wDjVev0UAfN/jf4jfH/AEXSbe88LfC2PU71r20ia3GqwuXgkmVZyG2osZWMswdyVGMEHIFWZpJJpnlmOXdiWJ9T1r6Hrz7W/Br3Ny93pjqvmHLRtwMnqQRn8q+e4gwNStCLpq9uh7WTYuFOUlPS55myqylWAIPBB5BFcxb634SutQPhzW/i/J4dEDtDDotulloSxoh2iKMzwfaXCAbQ0UoUjkDBGPUb7wN4lOlXUmlS2g1JU3W8dz5hgdwc7JGiKugYZXcuSpO7a2Np8v8ACXinxfHpF3Y6jp0/jXSdMcW+qaPfLE/iHSZMZ2ODiHUYCvzRSDbJJHhlM7EgRw9gatJSlUVr9Cs5xdOo4xg72PT7X4HfCa+SO91TS/8AhKd2HWXWbufWQT1DL9tkmQe20ADsBXqmmaTpWi2i2GjWcNhbJ92K3jWKMfRUAArw3w38OfgF44sn8QeArCHTsyMk0uhy3Gi3MU6/eSdbN7eWOVf4klAYfxCuh/4Vp4u0vnwt8RNYt1H3YNSjtdTg/FpYkuj/AOBH+NfSHhnsNFePeb8e9H+/B4d8Uxr1Mb3WiykeyMNQQn2LqD6ij/haWu6Zx4s+H+vacq9ZrSODVYT/ALq2UslwfxgB9qAPYaK8osvjl8Jby5Sxm8TWul3knC22qb9MuWPoIL1YZCfbbXoo1nSGeKJb6AvNC9xGokUl4YioeRRnlFLqGYcAsMnkUAaVZWu6HpHiXRr3QNftUvdO1CJobiGQZSSNxgg/4jkdRzXzZ4o+P2o/b5LfwrbRC1jJAmnVmaTH8QUEBQe2cn6dK4fxX8VfFPjrw23hSSO3tVunAuyk5s1urckBoHuHJ+zRMCWnlXc/lK6Rp5jqw3eHklc8uGcUJVPZp6/geLavcLqni9LrVdWkjttGwnhfUTbSXX/Cdy2MymK2vYIiPtZsmASNhh5STdIwjRwfeLXSLD9oOPV/Dv7S9iuiXFnbSSf8IhLMptraBlK/2i1yMJesM5SVP3ds2BtEy76yIPD+jeM9IJ8M6Zd+OvFBjjWy8QWqDSdG0UwkNAukzzBljgiKr/x6x3LSgYmLr8o4DXvB/j79pDxZF8EvjJro0zVPDKvd60mgQJaRpZTRmK3e1vJvNuJDf7iJApiRI0liliJMbNgeoed+CrLw/quma4niXxbcR61DbnTdN8P3Vpc6ul3okqRTQ6jBZKxvLb7cyJPvt5YYrdlVSoMVeE/Az4hfEPxt478N6B8QmfTvDfgSwuh4Xv5LCTV0urSO+liN99mtWUSNbeRHCkhDQw+UszIcqa9X+Mtzd+FUj8C+F9MtNLks559CudZ0e2aODxP5piknsZUAAN1borXE6NI/mvG1tExM00cfv/7Tun+BfBvwh+H3if4eamml33hlUbQdRgxK0WmGAG5uyePMSKMJOwP/AB8OFtzn7QQwBw/w4+GXwq+IHxS/4QXW9Xfx74G0T7RPod3d3Bmtri/EMZns7dYSlrD/AGcJmlj+zxxtl1UHNm1eg+L/ABRr+r6PfeALzUZNS+FkVxHFN49kTfcaZ5DFgiOOJZIJEXbqgHlQNzKHdGevPfDXwS0r9ojwoNIkso/h/q/hWziMM1srx6rq1zcQuYdSvZXVJHsLrfI3lOGkk3SrKyMHjrtfB2q/Fb4raNHodnZ2/ifwB4VnWx1jTnEGl6hc6hZDbNpivEBZXNtbOF3kR2sc3CZMYdWAOg/Z60yx8T6nbaN4vgUWehxyahoUc0bKPEcczGM+I7jzSzTTyKVXY5Ji3+YeJodn3ZFFHDGkMKCOOMBVVRgKBwAAOgFflv8AFe+u5Nf0z4dfBnVZPh5f20c2uz2+uWjxz+GrWF0guLnSFEirOkvneW1pFJJbPkiN4mBrtdY/a28Z/aEg8NWNtb2MACI10rzTyhRjdI28AFsZIGcf3j1r6jhzg/HZpzPCx0ju27L09fQxq4iMPiP0Wor5v+Cfx/tfibcP4f1u1TT9cjQyKIyTDcIv3igbJVl6lSTxyD1x7prvifw14XtftvibVrTSLf8A563k8dunH+1IyivLzjJsRgK7w2KjyyX5d0+qLp1FJXiblFePf8L2+Hl38vhme98UMfunRdPutRhb/t4gja3Ue7SAe9H/AAnXxN1bjw38Op7ZT92XXNRtrFD77bT7dKB7NGp9q8ss9hrkPEvw/wDAnjIY8XeHNO1rGMG8tIpyMdCDIpII7EdK43+x/jlrH/IQ8SaN4eibrHp+ny3s4+lzczJH+dr/AIUf8Kei1Hnxd4v8Ra/nqraidOiPsY9LWzUr7Nuz3zQBh678Ofhl4Jtft8fim/8AAcI6PHrk1varj0t7uSS1GP8Arl9a+Hp/ENnq2jeOLjTPHMvjl7rxSY7i4ls4IpLaCG1RLWD7ZaosN1HOkYulMe1U3quxGU5+zLyw+DPgDXjongXwVZ6942Kq5trK2ilvI1b7sl7ey5+zx9w00m5ufLV24rwm88JfE3xd8Y7rSpLiDW9B1YeX4msdObytM8PXpQNb3EE0wMl3fbURZlURL5blnjQumai7M9LKMXChiadWa0TPm+vff2etc8U6R4o1CLwxpv8AbLz2ZaS1M62ynZIgDmRgwBXcQOOckVs3v7LXj+G+MFjdWNzbE/LM0jx8erJtJB9hu+tfUXwk+Elh8MdPmZ5he6rehfPnA2qFXkRxg8hQeSTyx5OMADWc1Y/ReIeIMJPCSp05qTktF/n2sL/wmHxc/wCieR/+DmD/AONVyXjr4h/H3RvCmoap4T+GEWo6vbqrW1qdVik+0PvUeVwqbPMGV8wnbHnzGBVSD9GUVgflB5D8X/F3iHwf4U0rXdGdLaU6tpcd4jwm5IsZbhBebVQ7iYoN8pKqx2o33Rl1574NfFDXvG94dN8T/Zbe8uNB0rX47ZFaK6gi1ea8KwzRs5O6GKKFWO0fMxz1Fe06xoGheIbdLPX9OttTgjfzEjuoUmRX2lNwVwQDtZlz1wSOhNa1ABRRRQB//9X9/KKKKACiiigAooooAKKKKACvMfHXgW+1S+t/Gngu4j0zxfpkZjgnkB+z3lvnc1neKvLQseVYZeJzvT+JX9OooA+fbDS/DXxVluPE+kG68EfEDSCtrqDW5Rb62lUZWG7Qhoby3YfNEZFdHQ74mVuRrR/EnXfA8i6f8ZLOKxtshI/EFkGOlS54BuVYs9ix/wCmrND2ExJ21veOvAt9ql9b+NPBdxHpni/TIzHBPID9nvLfO5rO8VeWhY8qwy8Tnen8SvpeCfG2m+O9Nu4ZrR9P1XT3+zappdztM1pOVyUcD5XjdfmjkXKSIQynqAAdxFLFPEk8DiSOQBlZTlWU8ggjggipK8Ul+GuteCZX1L4N3kWnQEl5NAvCx0iYnk+QVDPYufWENFnJaBmO4dB4V+J2k67qg8La3azeG/FCoXbS7/assip96S1kUmK5iH9+Jm28BwjfLQB6Be2FjqVs9lqNvHdW8nDRyoHRh7qwINfPvib9nH4WQay3xH8MeHINM8R6Vp2oW9kLBBaQ7r6LZM7QwBFlkdBsDSbto+6ASTX0bRTTs7kzjzRce5+Y9X9LSSTUbYRRvKQ6ttjiadyFOTiJAzOcD7qgk9AK+xfE/wAE/DHiC+k1K1lk02eYlpBEFMbMep2noT3wQPam2fwL8FwaRdabdG5nmugv+lLM0FxA8biRHgeLaY3R1VgwOcjnIyK9CWKjbQ+OpcP1lUSlt3PKtR8f+LF8IXvijwz8TtM1+a3eO2hsbbR1F1LfTsI4LRomuw8UskhC4kUFRlmAUE14v4g+Efxru9Vt/C/g3x9Z/wDCyj9o1jV9bh0wxCwN9F5Zhkm85iyziNIYISnyRRLNgNEm7mPGWtRa38QLRvHkEOsXtq1xo/gvxLG39l+fdrMkF3qOoXFrLHNClqzLBG0e2Gd/MWMK00Sju/Feo/Ef4FxD4R/B3xAnxB8aeL53R/7ThVL61vbuFmOoXd/CRHsjjjaSOCSIyGOMKjeWmR5x9mea+HNRGqeGtQ1bxFr+nQaX4XjuvCtj4cfRoryd7iJI5tVPlm82HEihWupH27I2nZ1SQsfKfhn4B+K3w58VeEvGfxWvg/hnWbK5l8OC4sZNVHh6Lz5LpontpJUZy0TrOZW8yaNARtCQuyd9caF4X8I+INJ8PpbX1l4h0e0t4fFketyw20etWULwy22j2syPLaB32mWKNZg0iApOWNyzj69+N3xO8E+Jvh5pFr4a120tNU14xahpOpXMqwRaQbWQH+0LgyYKeQ4MZgbDTSE25GDIVAPloeEvjD4k8Ry/CT4V+PLB9T8F2Mklpq9tbLEjeHdRhD21h58dxIxMjnykwpMEccdyH3tGH9S8M2fjPwXa6d4+8H+KrPRvDt7JbaJ4gsDoixHR7q2H2eCWeEXRAaJikE7hsGIxy5aNA1eNeHbnxF4L8P6f8XP2fvC+pXVx4MW8Pi6x1B0hs7qaaJH1CS2aVkuTJKViu1VIVglVI2XyyxDer+KdK0PxH4Yuvjz4g8Vt4l0i+8mz8SeHbAS6NbXkABjFubZJftMt/EJAFinlYXKYiCYaMqAZ/wARtU18+J/iR4I1f4hWPifVJdJ0vUE0iysDFJBbWFyUu55ZlaRY8NLEGt2kO0ASgAytn5cr6u+B/gW1+IF/4dtLq5k8L6T4Kjiv/Dtrp+21m1vQribMUmpyW0myZcRrDPbHIEg8ycMZVRfb/Ef7JXgXVtRe+0e+udIjlYs0CBZYlz2TdhlHsScduOK/ZvDXj3CZdh54TGXSb5k0r7pKztr00PPxmFlN80T47+B/h2TxR8TNJ0rbKbdvNa5MMskDrB5bB/3kTK6bgduQw6471+lWhfCH4XeGrr7fovhXTbe96m6NtHJdNj+9O4aVvxY1B8OPhN4R+GFnLD4fieS6uQBNdTkNNIByFyAAqg9gB75PNemV8n4g8UUs1xyrUFaEVyq+71bv+OhvhaLhGzCio5pobaGS4uJFiiiUs7sQqqqjJJJ4AA6mvFn+I+v+O3ax+DlpFdWeSsniG+Vv7LTsTaopWS+YdjGyQ/8ATbIK18KdJ6N4r8Z+GfBGmjVPE9+llDI4iiXDSTTyt92KCFA0ksjdkjVmPYV5v5XxL+JnNyZ/APhl/wDlmjL/AG5dp/tOu6OxRh2XfPj+KBhiun8KfDLRvDmpHxNqdxP4h8TyoUk1bUCr3AVvvRwKoWO2iP8AzzhVFPVtzZY8/wCKPFGueMNcufhx8Obk2stqQms6ygDLpquA3kQbgVe9dSCqkFYVIkkBJSOQA53ybaKef4P/AAQgj0SG0fOt6xCof7C0oDMiO+4z6jMpDFpC/lgiWXJKJJ7X4X8L6H4N0O28O+HbYWtjag7VyWZmYlnkkdiWeR2JZ3YlmYlmJJJo8L+F9D8G6HbeHfDtsLWxtQdq5LMzMSzySOxLPI7Es7sSzMSzEkk1v0AFFFFABRRRQAUUUUAFFFFAH//W/fyiiigAooooAKKKKACiiigAooooAK8w8deBb7VL638aeC7iPTPF+mRmOGaQH7PeW+dzWd4q8tCx5Vhl4XO9P4lf0+igDh/Avjqx8bWNxm3k0zWNMkFvqWm3BH2iyuMZ2tjhkYfNHIuUkQhlPUDU8VeD/DXjbSzo/inT47+2DCRN+VeKVfuyxSKQ8Ui9VdGVlPQiuU8deBb7VL638aeC7iPTPF+mRmOGaQH7PeW+dzWd4q8tCx5Vhl4XO9P4lfX8C+OrHxtY3H+jyaZrGmSC31LTbgj7RZXGM7WxwyMPmjkXKSIQynqAAcRj4l/DP7vn+P8AwynYlf7dtE9j8kd8ij12T47zsa9J8KeMfDPjfTP7X8L36X1urmOQDKSwyr96KaJwskUi/wASOqsO4FdNXgfxd+E/hjxBdWXxGa7u9D1XwzPBqUk+ltHBNqIsHE0NpeM6OJbcsuCjLuGfkdOctIUpJK7Pa9Q1jSdJVX1W9gs1boZpFjB+m4ivnn4+/Fm20PQLDwh4Su2ute8Xuba3/s91e5S3yFleAg4Ez7hFCScK7ea37uKQj5x1jWNR17UJtU1Wdri4mOWZj09AB2A7AcCqlrDaXM4tb23juYLnEMiSO8SvGzKWjeSP94sb4CyhT88e5GBViD2PB6b6nzVPiNOpyuPunqnw+8J33ibRr3w34US0FvqMCafrOvLEtxYW9nbqY00fRIplZJ47dSyNO6mLeXkYSys0afPll8QvB/7PHi/Wr/wBbTeN9E0ae80TRdEtGa+1eDUZgrXVyzIjNJDNcQ+QXuJPORIXaIyRkIPTfiF4/wDhrP4Nj0fUvjToOoahqjw6Xp2maNqdppejWPnfKZ5IoLhp5IbWINIyzTmJ9gQRgsFN34ffFX9l7wkG8RWnjLw5pHg34e20um+HrCK/tPOmaNfLvNQ8hH3yzXBXyYCFLum91yLiuI+mNHTL/wAfQ/Ce0nE+nQnxrK0irbeRq+q+INTvQWfaXDWNtGApByLtILePk4TFcHpn7Jtp+zjeaf8AFzw3qjR3xQ/8JFdCzhvYbN3dpBd21tKmY7SEvsmjt2hfygsoYFJFk1PD3i/4daP4guvjronxA8I2niPVWmkfwvNrWnpZxWc+wtHHKspEGoy+WrzzrmOR/wB24Kqso9Muv20fg/4rt4NC+HnizRI9avEP2qTWb63trTSVBKObnMqieQEHZDA7CThvMWIiQgHIfEv4veLPgR4vs/Hnijw/b+IrTxBZPDqQ8OS+eL22t0L2+ovZS/vYFgLeXLIrTx+TIC0mY40PJ/A7wFpPifxJqmqaR4lspPiF4N+zvo/lAXGnW+jyo4gsZrd0inZrdjLatNIFuo0WNlMaSeW3QfDzxr+zv8EtbuPCd58QvDviTw94yQQnU59SsJJrWZYyDYXCo+yOwcbjaqqrFCxaEgB48+eeLPGn7P8AY3Nr/afjTRb/AFL4bypJp+pWetQxahf+GLs+XJbpd28yzNdWOAwRX3yeTESD57CgDZ+LHxH0/wCCl5L8Tb9E8KXnh+4e/wBQ0a4lBEM1ydtzJYOAPtVhqQG2Xy1zDciK4eNGWZa+5/C/xe8EeJPCei+L7m9Hh6DXraO7t7XWHjsrwQyjKF4XfKllwwB5AIyAcgfAvjbxD4J8X+L77U9O+Ith8TdP+Gthb3WmWsrie7tdU1SdVguxc2fk2tzDFFE6YkWZyxKygAgyeE3t9ealdzX+oTvc3NwxeSWRizux6kk8k1+mcDeHcs3pzxFSpyQTtortvf5JXRx4nF+zdktT9uLe5t7yBLm0lWaGQZV0YMrD1BHBFec+KPifpWi6o3hXw/aTeJvFG1W/syx2l4Vf7sl3MxEVtGezSsCwz5au3y1+fXwM8Sa/L4jt/h3Hrl7pWjeIJPLmNm4SZGALDyXZWMRkICO6YfaSVKsFYfpd4X8I+G/BWlrovhbT4tOtAzSMsYJaSRvvSSuxLySMeWdyWY8kk187xhwtUynF/V5y5k1dPa69Oj0NcPXVSNzzeH4Z6x4zmTU/jJexarGrB4tCtNw0eAg5HnBgHvXH96YCPOCsKEZr2lESNFjjUKigAADAAHQAU6vF/FHijXPGGuXPw4+HNybWW1ITWdZQBl01XAbyINwKveupBVSCsKkSSAkpHJ8qbh4o8Ua54w1y5+HHw5uTay2pCazrKAMumq4DeRBuBV711IKqQVhUiSQElI5PSfC/hfQ/Buh23h3w7bC1sbUHauSzMzEs8kjsSzyOxLO7EszEsxJJNHhfwvofg3Q7bw74dtha2NqDtXJZmZiWeSR2JZ5HYlndiWZiWYkkmt+gAooooAKKKKACiiigAooooAKKKKAP/9f9/KKKKACiiigAooooAKKKKACiiigAooooAK8w8deBb7VL638a+CriPTPF+mRmOGaQH7PeW+dzWd4q8tCx5Vhl4XO9P4lf0+igDhvAvjqx8bWNx/o8mmaxpkgt9S024I+0WVxjO1scMjD5o5FykiEMp6gdTq2mwaxpd3pNzkRXkTxMR1AcEZHuM1wHjrwLfapfW/jXwVcR6Z4v0yMxwzSA/Z7y3zuazvFXloWPKsMvC53p/Er63gXx1Y+NrG4/0eTTNY0yQW+pabcEfaLK4xna2OGRh80ci5SRCGU9gITSasz4q8UeDNf8JX0lnqls4RSQkyqTFIOxVunPp1Heun+H/wANtf8AFV+lziTTrGH5/tTID845Xy1cYc5wTkEY6+h+568S/aA+JI+Gnw7ur60uDBq+quLDTyq+Y6zzKS0qRjlzDGryhBy7KEHzMAet4ttWsfP0+HqcanNzadj5C8UeM/ij4h8dahaanDH4h0uztrvTBq2if6Hc2ekW86prN+LW4lKCSd1FnDIlxvBhmkijIBB90+FvinwJ8YNbttds7u3sfDfg2Nf7B0GX/RriNIk2Lqd1aSbZI12fLaKygJHmQ/O4EflvgHw/odv4WuZPGMqaZ4N0+SBNbkZjN/aN1a/urTRICoLT29n9y42Am7u2kUA7plb2zWvhTD+0JJa6n8YdCSz8L2ZL6dosgC30hIwJ72eM74sg/LbROAP+WzOf3ach9CdLJ4i8R/F92sfAF1Lo3g/JW419BtuL4Dho9LDDiM9DdsMf88AxPmJo3/wV8OWFpY3Pw52+Edd0iNo7S+t08zzEZi7xXqMQbuKRyWcSNv3EurrId9cl4mOsfBWxhutL8eWr6YSI7fSfE7mV5SOkNpeQg3Zb0Dx3beg9OVuP2kPFtxDaw3fgyfwDFcj5tZ8ULNFpSHOAUMSbznqFuzZMR9MUAerad4o0zxrHffCv4raTFput3NtItxYSt5lnqNtjDz2UxC+bHyCy/LLCcb1X5Wb5l174jf6db/Djw9PL468c+Fbkz+GL+yaKePUYVQi40/UbpnSBJRBuiuQz5ZSlwqGRWVPcta+APhf4t6LG3xa1668dQzDzrYRSiy063cqQstrBasAxAJ2tO87YJG4g4rG1mx/sHRLX4Y/FR1tNKSWIaB4psYo7Vba7jP8Ao3noiiO0ulY4Vwot58lMJv8AJIB83fCDwn43+JDeJvCdy+k6H4fuNGiksLFYTLqQ8q6b+z1nvSkTn7AI57CeEo3leWm3liz+K+I/B3ifwlqL6V4h02ayuEYqA6Ha/ujD5WB7FSRX0H4g8T638J/iJbePNdgS0vNNvTDr8EA2xyrdpGs19axklvsmoRpHKByFv7X7PlpJJCf0at7iC7gjurWRZoZlDo6EMrKwyCCOCCOQa/QuDPEGvlEJUfZqcG72vZp7aOz/ACOXEYVVNbnwB+zV8HvEEnie28e+IbOSx0/TgzWyzKUeeVlKhgpwdigk7uMnGM84/QWivF/FHijXPGGuXPw4+HNybWW1ITWdZQBl01XAbyINwKveupBVSCsKkSSAkpHJ4PFPE1bNcV9ZrK2lkl0X9Pc0oUVCNkHijxRrnjDXLn4cfDm5NrLakJrOsoAy6argN5EG4FXvXUgqpBWFSJJASUjk9J8L+F9D8G6HbeHfDtsLWxtQdq5LMzMSzySOxLPI7Es7sSzMSzEkk0eF/C+h+DdDtvDvh22FrY2oO1clmZmJZ5JHYlnkdiWd2JZmJZiSSa36+bNgooooAKKKKACiiigAooooAKKKKACiiigD/9D9/KKKKACiiigAooooAKKKKACiiigAooooAKKKKACvGfix4M8TXduPHXwrFtbePtLjWK1e6kaGzvLdnBktb4ors0GCzqQu+NxuQjLBvZq5nxot2/hDWlsc+ebOfbjrnYenvjpTSuyKkuWLZ4Fc/H3UbCxsrEWMF5qUMES3s6yMbZrkIPO8j5VZo9+drEKSOdor5x+J0viv4x+P9A14yOlnosHk2+mWJK3T3M8o3ywTORGsjYjAeTaLcIZ1YvGqtBWjpFidT1Wz05YUuftU0cXlSKHRw7AFXU8Mpzgg8Eda9KWGjY+Ko55X9qm3p2PXfBl54U0y+spobY+PfE2iJ9m0/SvDkQm0bQEC7PJhuZTHapMF+WSeeVZ3GdiIhMdex/2L8YPGHzeINYt/BWnP1tNGxeX7L6PfXMYiTI6rFb7h/DL0NMsdE+N+mWkWn6bf+FbS1gUJHFDpd5HGijoFVbwAD2FW/sfx9/6C/hn/AMF17/8AJleYfcHReFfhl4I8G3UmqaNpofVZ12zajdO93qEw9JLudnmYei79o7AV3bKrqUcBlYYIPIINeRfY/j7/ANBfwz/4Lr3/AOTKPsfx9/6C/hn/AMF17/8AJlAC3fwY8NWlzLqfgK6uvBGoSsXd9IdYraVzyWmsZFe0kJP3mMXmdcOCc1l3+ofE7RLGfSvHXhu08eaHcI0U0+kqsVw8TDDCfTbtyjrj73lXDlucRDgVp/Y/j7/0F/DP/guvf/kyj7H8ff8AoL+Gf/Bde/8AyZQB+fHx587xPZ2/wr+COrJe3klrczKNX3WuoeEdNDRRXT3Ed75c89iDJGVhZHmhdUki37Igm58JfjhrHwU+Hej/AA2066uPGp0hWSTV9WdopbnLHasVsjMttDGmI4og7BUUd816l8VvBXxhhg8f+M/HQ0K+sprLSLSwutPs2h1CKKOdnu4d7l5BaljE4VpGJk8w4VNufi+v3Dwu4KwOOw08XjI875uVK7srJO+nV3PNxuIlFqMT9FfDnxr1r41RReDPB6f8Ivqk6s+oXryJK1vaLgM1kpH7y4cnCl1CRcud+AjfSnhfwvofg3Q7bw74dtha2NqDtXJZmZiWeSR2JZ5HYlndiWZiWYkkmvy9/Z7TUH+MHh7+zs7lklMmOgi8p/Mz7bc/jiv1hr4/xH4bw+WY9UsN8MoqVt7atW9NNLnRg6znC8gooor8/OoKKKKACiiigAooooAKKKKACiiigAooooA//9H9/KKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD5/8AFHwF0vVb6S/0G9/s3ziWaFo/MjBPXZgqVHtyPTA4ro/Anwh0fwbdjVbic6jqCghHZdiR54JVcnnHGSfoBXrtFautJq1zghllCM/aKOoUUUVkd4UUUUAFFFFAFa9srTUbOfT7+Jbi2uUaOSNxlXRxhlI7givjXxH+x5pt1qT3PhjXmsLSRiRBPD5xjB7K4dSQOwIz6k9a+06K97I+Jsdl0pPB1OW+60afyd0ZVKMZ/Ejxn4UfBPw18KoprmzkbUNVuV2S3cqhSEznZGgzsUkAnkknqcAAezUUV5+Y5lXxdZ18TNyk+rLhBRVkFFFFcJQUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB//9k=)\n",
        "\n",
        "Como vimos, dado un sistema de pesos y sesgos, $w, b$, esta red define una función de salida (o forward method)\n",
        "$$\n",
        "y = g_{w, b}(x)\n",
        "$$\n",
        "\n",
        "Nuestro objetivo que esta red sea una buena representación de una función objetivo dada\n",
        "$$\n",
        "z=f(x),\n",
        "$$\n",
        "con lo que tenemos que encontrar el sistema de pesos tal que $g_{w, b}$ aproxime a $f$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfWPIQRjTbt8"
      },
      "source": [
        "## Función de costo\n",
        "\n",
        "Para medir la proximidad de $g_{w, b}$ a $f$ se define un costo (o función de pérdida -- \"loss function\")\n",
        "$$\n",
        "C(g_{w, b},f) = C(y, z).\n",
        "$$\n",
        "Como ejemplo de esta función tomamos el costo cuadrático medio\n",
        "$$\n",
        "C(y, z) = \\frac12 |y-z|^2,\n",
        "$$\n",
        "aunque otros costos son posibles y vimos varios de esos en la materia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5N-sRfjUCf2"
      },
      "source": [
        "## Conjunto de entrenamiento\n",
        "\n",
        "Típicamente, no conocemos la función objetivo $f(x)$ sino que conocemos una serie de valores de $f$: $\\{(x_i, z_i)\\}_{i\\in I}$, donde $I$ es un conjunto finito. Notamos a este conjunto de entrenamiento como $T$ (de *Train set*).\n",
        "Luego, la función de costo que se toma es\n",
        "$$\n",
        "\\frac{1}{\\# I}\\sum_{i\\in I} C(y_i, z_i),\n",
        "$$\n",
        "donde $y_i = g_{w, b}(x_i)$ (es decir, la salida de la red con entrada $x_i$).\n",
        "\n",
        "Para el error cuadrático medio, se tiene\n",
        "$$\n",
        "\\frac{1}{\\# I} \\sum_{i\\in I} \\frac12 |y_i-z_i|^2.\n",
        "$$\n",
        "Observemos que este error resulta ser función del sistema de pesos y sesgos $(w, b)$, es decir\n",
        "$$\n",
        "C(w, b) = \\frac{1}{\\# I}\\sum_{i\\in I} C(y_i, z_i) = \\frac{1}{\\# I}\\sum_{i\\in I} C(g_{w, b}(x_i), z_i).\n",
        "$$\n",
        "\n",
        "Luego el objetivo es el de encontrar el sistema de pesos y sesgos que minimicen este error\n",
        "$$\n",
        "(w^*, b^*) = \\text{argmin}_{(w, b)} C(w, b).\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18E9m0pvWA7p"
      },
      "source": [
        "## Descenso de gradiente\n",
        "\n",
        "Para encontrar ese sistema de pesos y sesgos óptimos se utiliza *el método de descenso de gradiente*\n",
        "\n",
        "Esto consiste en usar el concepto de que el vector $-\\nabla_{w, b} C(w, b)$ es el vector que apunta en la dirección de máximo decrecimiento de la función $C(w, b)$\n",
        "\n",
        "Se define un hiperparámetro $\\eta>0$ llamado *tasa de aprendizaje* (learning rate) y se toma un valor inicial de pesos y sesgos de forma aleatoria $(w_0, b_0)$. Luego, se define la siguiente secuencia recursiva\n",
        "$$\n",
        "w_{k+1} = w_k - \\eta \\nabla_w C(w_k, b_k)\\quad \\text{y}\\quad b_{k+1} = b_k - \\eta \\nabla_b C(w_k, b_k).\n",
        "$$\n",
        "\n",
        "Heurísticamente se espera que el costo vaya descendiendo a medida que avanzamos con esta secuencia de pesos y sesgos y se continúa hasta que el costo sea admisible.\n",
        "\n",
        "Cada paso de iteración se lo denomina una *época* de entrenamiento. El número de épocas de entrenamiento es un hiperparámetro del algoritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8BwIHBcX_px"
      },
      "source": [
        "## Repaso de notación de la red\n",
        "\n",
        "El número de capas de una red la notamos por $L$, y las enumeramos usando el super-índice $0\\le \\ell\\le L$. La capa $\\ell=0$ es la capa de entrada, la capa $\\ell=L$ es la salida de la red y las capas $1\\le\\ell\\le L-1$ son las capas ocultas.\n",
        "\n",
        "La cantidad de neuronas de la capa $\\ell$ se nota por $d^{(\\ell)}$. El sesgo asociado a la $j-$ésima neurona de la capa $\\ell$ se nota por $b_j^{(\\ell)}$ y el peso que conecta la $i-$ésima neurona de la capa $\\ell-1$ con la $j-$ésima neurona de la capa $\\ell$ se nota por $w_{ij}^{(\\ell)}$.\n",
        "\n",
        "La salida de la capa $\\ell-1$, que es la entrada de la capa $\\ell$, se nota por $\\mathbf x^{(\\ell-1)} = (x_1^{(\\ell-1)},\\dots,x_{d^{(\\ell-1)}}^{(\\ell-1)})^T$, $\\ell=1,\\dots, L$. Recordemos que $\\mathbf x^{(0)}$ son las entradas de la red.\n",
        "\n",
        "La $j-$ésima neurona de la capa $\\ell$, toma las entradas de esa capa y primero calcula la *señal*\n",
        "$$\n",
        "s_j^{(\\ell)} = \\sum_{i=1}^{d^{(\\ell-1)}} w_{ij}^{(\\ell)} x_i^{(\\ell-1)} - b_j^{(\\ell)}.\n",
        "$$\n",
        "\n",
        "Matricialmente, el vector de señales $\\mathbf s^{(\\ell)} = (s_1^{(\\ell)},\\dots,s_{d^{(\\ell)}}^{(\\ell)})^T$, se calcula como\n",
        "$$\n",
        "\\mathbf s^{(\\ell)} = W^{(\\ell)^T} \\mathbf x^{(\\ell-1)} - \\mathbf b^{(\\ell)},\n",
        "$$\n",
        "donde $W^{(\\ell)} = (w_{ij}^{(\\ell)})$ ($1\\le i\\le d^{(\\ell-1)}$, $1\\le j\\le d^{(\\ell)}$) es la matriz de pesos que conecta la capa $\\ell-1$ con la capa $\\ell$ y $W^{(\\ell)^T}$ es su transpuesta.\n",
        "\n",
        "Luego, la neurona toma la señal $s_j^{(\\ell)}$ y le aplica la función de activación $\\phi$ para producir la salida\n",
        "$$\n",
        "x_j^{(\\ell)} = \\phi(s_j^{(\\ell)}) = \\phi\\left(\\sum_{i=1}^{d^{(\\ell-1)}} w_{ij}^{(\\ell)} x_i^{(\\ell-1)} - b_j^{(\\ell)}\\right).\n",
        "$$\n",
        "\n",
        "El vector de salida de la capa $\\ell$ es entonces $\\mathbf x^{(\\ell)} = (x_1^{(\\ell)},\\dots, x_{d^{(\\ell)}}^{(\\ell)})^T$ y la salida de la red es\n",
        "$$\n",
        "\\mathbf y = \\mathbf x^{(L)}.\n",
        "$$\n",
        "\n",
        "Para nuestra red, asumiremos que todas las capas tienen la misma función de activación, $\\phi$, menos la última que asumiremos que tiene función de activación lineal, con lo que\n",
        "$$\n",
        "y_j = x_j^{(L)} = \\sum_{i=1}^{d^{(L-1)}} \\lambda_{ij} x_i^{(L-1)},\n",
        "$$\n",
        "donde $\\lambda_{ij} = w_{ij}^{(L)}$ y $b_j^{(L)} = 0$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtnAC-7wfL2r"
      },
      "source": [
        "## Backpropagation -- Cálculo de $\\nabla_{w, b} C$\n",
        "\n",
        "Este es el algoritmo más importante de todo el ciclo de entrenamiento: el cálculo de $\\nabla_{w, b} C$. El objetivo es dar un mecanismo para el cálculo que sea simple de implementar computacionalmente.\n",
        "\n",
        "Empecemos calculando $\\partial_{\\lambda_{ij}} C$.\n",
        "\n",
        "Recordemos que $C = C(y)$ y que $y = \\mathbf x^{(L)} = \\mathbf s^{(L)} = (s_1^{(L)},\\dots,s_{d^{(L)}}^{(L)})$, con $s_j^{(L)} = \\lambda_{1j}x_1^{(L-1)} + \\cdots + \\lambda_{d^{(L-1)}j} x_{d^{(L-1)}}^{(L-1)}$.\n",
        "\n",
        "De estas expresiones observamos que el peso $\\lambda_{ij}$ sólo aparece en la señal $s_j^{(L)}$, luego\n",
        "$$\n",
        "\\partial_{\\lambda_{ij}} C = \\frac{\\partial C}{\\partial s_j^{(L)}} \\frac{s_j^{(L)}}{\\partial \\lambda_{ij}} = \\delta_j^{(L)} x_i^{(L-1)},\n",
        "$$\n",
        "donde\n",
        "$$\n",
        "\\delta_j^{(L)} = \\frac{\\partial C}{\\partial s_j^{(L)}} = \\frac{\\partial C}{\\partial y_j}\\qquad \\left(\\frac{\\partial C}{\\partial y_j} = (y_j-z_j)\\ \\text{para el costo cuadrático medio}\\right)\n",
        "$$\n",
        "\n",
        "Calculemos ahora las derivadas respecto a los demás pesos, $\\partial_{w_{ij}^{(\\ell)}} C$.\n",
        "\n",
        "Al igual que antes, observemos que el peso $w_{ij}^{(\\ell)}$ sólo aparece en la señal $s_j^{(\\ell)}$, luego\n",
        "$$\n",
        "\\frac{\\partial C}{\\partial w_{ij}^{(\\ell)}} = \\frac{\\partial C}{\\partial s_j^{(\\ell)}} \\frac{\\partial s_j^{(\\ell)}}{\\partial w_{ij}^{(\\ell)}} = \\delta_j^{(\\ell)} x_i^{(\\ell-1)},\n",
        "$$\n",
        "donde\n",
        "$$\n",
        "\\delta_j^{(\\ell)} = \\frac{\\partial C}{\\partial s_j^{(\\ell)}}.\n",
        "$$\n",
        "Análogamente\n",
        "$$\n",
        "\\frac{\\partial C}{\\partial b_j^{(\\ell)}} = - \\delta_j^{(\\ell)}.\n",
        "$$\n",
        "Queda entonces calcular los $\\delta_j^{(\\ell)}$ para $\\ell=1,\\dots,L-1$.\n",
        "\n",
        "Para esto usamos la regla de la cadena:\n",
        "$$\n",
        "\\delta_i^{\\ell-1} = \\frac{\\partial C}{\\partial s_i^{(\\ell-1)}} = \\sum_{j=1}^{d^{(\\ell)}} \\frac{\\partial C}{\\partial s_j^{(\\ell)}} \\frac{{\\partial s_j^{(\\ell)}}}{\\partial s_i^{(\\ell-1)}} = \\sum_{j=1}^{d^{(\\ell)}} \\delta_j^{(\\ell)} \\frac{{\\partial s_j^{(\\ell)}}}{\\partial s_i^{(\\ell-1)}}\n",
        "$$\n",
        "\n",
        "Finalmente, de la expresión\n",
        "$$\n",
        "s_j^{(\\ell)} = \\sum_{i=1}^{d^{(\\ell-1)}} w_{ij}^{(\\ell)} x_i^{(\\ell-1)} - b_j^{(\\ell)} = \\sum_{i=1}^{d^{(\\ell-1)}} w_{ij}^{(\\ell)} \\phi(s_i^{(\\ell-1)}) - b_j^{(\\ell)},\n",
        "$$\n",
        "obtenemos\n",
        "$$\n",
        "\\frac{{\\partial s_j^{(\\ell)}}}{\\partial s_i^{(\\ell-1)}} = w_{ij}^{(\\ell)} \\phi'(s_i^{(\\ell-1)})\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WSVnOHBy2nv"
      },
      "source": [
        "## Ecuaciones Maestras\n",
        "\n",
        "Llegamos a las ecuaciones maestras que arman el *algoritmo de retropropagación*\n",
        "\\begin{align}\\tag{1}\n",
        "x_j^{(\\ell)} &= \\phi\\left(\\sum_{i=1}^{d^{(\\ell-1)}} w_{ij}^{(\\ell)} x_i^{(\\ell-1)} - b_j^{(\\ell)}\\right),\\quad \\ell=1,\\dots,L-1\\\\ \\tag{2}\n",
        "s_j^{(\\ell)} &= \\sum_{i=1}^{d^{(\\ell-1)}} w_{ij}^{(\\ell)} x_i^{(\\ell-1)} - b_j^{(\\ell)}\\\\ \\tag{3}\n",
        "y_j &= x_j^{(L)} = \\sum_{i=1}^{d^{(L-1)}} \\lambda_{ij} x_i^{(L-1)}\\\\ \\tag{4}\n",
        "\\delta_j^{(L)} &= \\frac{\\partial C}{\\partial y_j}\\\\ \\tag{5}\n",
        "\\delta_i^{(\\ell-1)} &= \\phi'(s_i^{(\\ell-1)})\\sum_{j=1}^{d^{(\\ell)}} w_{ij}^{(\\ell)} \\delta_j^{(\\ell)},\\quad \\text{(fórmula de retropropagación de deltas)}\\\\ \\tag{6}\n",
        "\\partial_{\\lambda_{ij}} C &= x_i^{(L-1)}\\delta_j^{(L)}\\\\ \\tag{7}\n",
        "\\partial_{w_{ij}^{(\\ell)}} C &= x_i^{(\\ell-1)} \\delta_j^{(\\ell)}\\\\ \\tag{8}\n",
        "\\partial_{b_j^{(\\ell)}} C &= -\\delta_j^{(\\ell)}.\n",
        "\\end{align}\n",
        "\n",
        "Las ecuaciones (1), (2) y (3) son el forward method. Es decir el cálculo de la salida de la red.\n",
        "\n",
        "Las ecuaciones (4) y (5) son el algoritmo de retropropagación para el cálculo de deltas.\n",
        "\n",
        "Finalmente, las ecuaciones (6), (7) y (8) son el cálculo del gradiente de la función de costo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def neural_network_regression(X_train, y_train, d, nabla, phi, d_phi):\n",
        "    '''\n",
        "    inputs:\n",
        "\n",
        "    d : list of L+1 integers where d[i] is the number of neurons in layer i\n",
        "        d[0] : number of featuress\n",
        "        d[L] : number of output neurons\n",
        "    X_train: training data with shape (n_samples, d[0])\n",
        "    y_train: training labels with shape (n_samples, d[L])\n",
        "\n",
        "    nabla : learning rate > 0\n",
        "    phi : activation function to apply to the output layer\n",
        "        e.g. sigmoid, relu, softmax, etc.\n",
        "\n",
        "    d_phi : derivative of the activation function\n",
        "\n",
        "    outputs:\n",
        "    W : list of L matrices where W[l, i, j] is the weight from input i to the neuron j in the layer l\n",
        "    B : list of L vectors where B[l, j] is the bias from the neuron j in the layer l\n",
        "    '''\n",
        "    N = len(X_train)\n",
        "    W, B = initialize_parameters(d)\n",
        "\n",
        "    d_cost_W, d_cost_B = initialize_gradients_per_sample(N) # N x dim(W), N x dim(B)\n",
        "\n",
        "    # loop epocas:\n",
        "    for _ in range(10):\n",
        "        for i in range(N):\n",
        "            # batch training\n",
        "            x_0 = X_train[i]\n",
        "            y_0 = y_train[i]\n",
        "\n",
        "            X = forward_propagation(x_0, W, B, phi)\n",
        "            delta = backpropagation(X, y_0, W, B, d_phi)\n",
        "\n",
        "            d_cost_W[i] = gradient_W(X, delta)\n",
        "            d_cost_B[i] = gradient_B(delta)\n",
        "\n",
        "        # average gradients\n",
        "        d_cost_W_mean = np.mean(d_cost_W, axis=0)\n",
        "        d_cost_B_mean = np.mean(d_cost_B, axis=0)\n",
        "\n",
        "        # gradient descent algorithm\n",
        "        W, B = gradient_descent(W, B, d_cost_W_mean, d_cost_B_mean, nabla)\n",
        "    \n",
        "    return W, B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[5, 0, 3, 3],\n",
              "        [7, 9, 3, 5]],\n",
              "\n",
              "       [[2, 4, 7, 6],\n",
              "        [8, 8, 1, 6]],\n",
              "\n",
              "       [[7, 7, 8, 1],\n",
              "        [5, 9, 8, 9]]], dtype=int32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "s = np.random.randint(low=0, high=10, size=(3, 2, 4))\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5fq3BMTmeqt"
      },
      "source": [
        "## Forma matricial de las ecuaciones maestras\n",
        "\n",
        "Para la implementación es mejor escribir las ecuaciones (1)--(8) en forma matricial que es como trabaja el código.\n",
        "Los datos entonces se toman\n",
        "$$\n",
        "\\mathbf x^{(\\ell)} = (x_1^{(\\ell)},\\dots,x_{d^{(\\ell)}}^{(\\ell)})^T,\\ W^{(\\ell)} = (w_{ij}^{(\\ell)})_{i,j},\\ \\mathbf b^{(\\ell)} = (b_1^{(\\ell)},\\dots,b_{d^{(\\ell)}}^{(\\ell)})^T\n",
        "$$\n",
        "$$\n",
        "\\delta^{(\\ell)} = (\\delta_1^{(\\ell)},\\dots,\\delta_{d^{(\\ell)}}^{(\\ell)})^T,\\ \\mathbf s^{(\\ell)} = (s_1^{(\\ell)},\\dots,s_{d^{(\\ell)}}^{(\\ell)})^T\n",
        "$$\n",
        "con la convención de que aplicar la función de activación $\\phi$ sobre un vector es hacerlo componente a componente. Entonces las ecuaciones quedan\n",
        "\\begin{align}\n",
        "\\mathbf x^{(\\ell)} &= \\phi\\left(W^{(\\ell)^T} \\mathbf x^{(\\ell-1)} - \\mathbf b^{(\\ell)}\\right)\\\\\n",
        "\\delta^{(L)} &= \\nabla_{\\mathbf y}C(\\mathbf x^{(L)}, \\mathbf z) \\odot \\phi'(\\mathbf s^{(L)})\\\\\n",
        "\\delta^{(\\ell-1)} &= (W^{(\\ell)}\\delta^{(\\ell)})\\odot \\phi'(\\mathbf s^{(\\ell-1)})\\\\\n",
        "\\frac{\\partial C}{\\partial W^{(\\ell)}} &= \\mathbf x^{(\\ell-1)} \\delta^{(\\ell)^T}\\\\\n",
        "\\frac{\\partial C}{\\partial \\mathbf b^{(\\ell)}} &= -\\delta^{(\\ell)},\n",
        "\\end{align}\n",
        "donde $\\odot$ es el producto de Hadamard entre vectores que consiste en multiplicar componente a componente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1kV_Z813mzp"
      },
      "source": [
        "## Descenso de gradiente\n",
        "\n",
        "Finalmente, la iteración para el descenso de gradiente se construye como\n",
        "\\begin{align}\n",
        "\\lambda_{ij}(k+1) &= \\lambda_{ij}(k) - \\eta x_i^{(L-1)}\\delta_j^{(L)}\\\\\n",
        "w_{ij}^{(\\ell)}(k+1) &= w_{ij}^{(\\ell)}(k) - \\eta x_i^{(\\ell-1)}\\delta_j^{(\\ell)}\\\\\n",
        "b_j^{(\\ell)}(k+1) &= b_j^{(\\ell)}(k) + \\eta \\delta_j^{(\\ell)}.\n",
        "\\end{align}\n",
        "Observemos que en las ecuaciones de arriba las salidas $x_i^{(\\ell-1)}$ dependen de la iteración lo mismo que los deltas $\\delta_j^{(\\ell)}$."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
